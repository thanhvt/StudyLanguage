'use client';

import { useState, useRef, useCallback, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Card } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Switch } from '@/components/ui/switch';
import { Label } from '@/components/ui/label';
import { api } from '@/lib/api';
import { showError } from '@/lib/toast';

interface ScriptLine {
  speaker: string;
  text: string;
  isUserTurn: boolean;
}

interface InteractiveListeningProps {
  topic: string;
  onBack: () => void;
  duration?: number;
  autoPlay?: boolean;
  handsOnlyMode?: boolean;
}

/**
 * InteractiveListening Component
 *
 * M·ª•c ƒë√≠ch: Cho ph√©p user tham gia v√†o h·ªôi tho·∫°i v·ªõi AI
 * Flow:
 *   1. AI sinh script v·ªõi YOUR TURN markers
 *   2. AI ƒë·ªçc t·ª´ng ph·∫ßn
 *   3. D·ª´ng l·∫°i ·ªü YOUR TURN ƒë·ªÉ user n√≥i
 *   4. AI ph·∫£n h·ªìi d·ª±a tr√™n user input
 */
export function InteractiveListening({ 
  topic, 
  onBack,
  duration = 5,
  autoPlay: initialAutoPlay = false,
  handsOnlyMode: initialHandsOnlyMode = false
}: InteractiveListeningProps) {
  // Script state
  const [scenario, setScenario] = useState<string | null>(null);
  const [script, setScript] = useState<ScriptLine[] | null>(null);
  const [currentIndex, setCurrentIndex] = useState(0);
  const [conversationHistory, setConversationHistory] = useState<{ speaker: string; text: string }[]>([]);

  // UI state
  const [isGenerating, setIsGenerating] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isAiSpeaking, setIsAiSpeaking] = useState(false);
  const [isComplete, setIsComplete] = useState(false);

  // Settings state (inline controls)
  const [autoPlay, setAutoPlay] = useState(initialAutoPlay);
  const [handsOnlyMode, setHandsOnlyMode] = useState(initialHandsOnlyMode);

  // Audio refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const hasInitialized = useRef(false);

  /**
   * Sinh h·ªôi tho·∫°i t∆∞∆°ng t√°c t·ª´ AI
   */
  const generateScript = useCallback(async () => {
    setIsGenerating(true);

    try {
      // S·ª≠ d·ª•ng API client c√≥ x√°c th·ª±c
      const response = await api('/ai/generate-interactive-conversation', {
        method: 'POST',
        body: JSON.stringify({ topic }),
      });

      if (!response.ok) throw new Error('L·ªói sinh h·ªôi tho·∫°i');

      const data = await response.json();
      setScenario(data.scenario);
      setScript(data.script);
      setCurrentIndex(0);
      setConversationHistory([]);
      setIsComplete(false);
    } catch (err) {
      showError(err instanceof Error ? err.message : 'L·ªói t·∫°o h·ªôi tho·∫°i');
    } finally {
      setIsGenerating(false);
    }
  }, [topic]);

  /**
   * Auto-generate on mount (Improvement #2: lo·∫°i b·ªè double confirmation)
   */
  useEffect(() => {
    if (!hasInitialized.current && topic) {
      hasInitialized.current = true;
      generateScript();
    }
  }, [generateScript, topic]);

  /**
   * AI ƒë·ªçc c√¢u hi·ªán t·∫°i b·∫±ng TTS
   */
  const speakCurrentLine = useCallback(async () => {
    if (!script || currentIndex >= script.length) return;

    const line = script[currentIndex];
    if (line.isUserTurn) return; // Kh√¥ng ƒë·ªçc ph·∫ßn c·ªßa user

    setIsAiSpeaking(true);

    try {
      const response = await api('/ai/text-to-speech', {
        method: 'POST',
        body: JSON.stringify({
          text: line.text,
          voice: 'nova',
        }),
      });

      if (!response.ok) throw new Error('L·ªói TTS');

      const data = await response.json();
      const audioDataUrl = `data:audio/mpeg;base64,${data.audio}`;

      // Ph√°t audio
      if (audioRef.current) {
        audioRef.current.src = audioDataUrl;
        audioRef.current.play();
        audioRef.current.onended = () => {
          setIsAiSpeaking(false);
          // Th√™m v√†o history
          setConversationHistory(prev => [...prev, { speaker: line.speaker, text: line.text }]);
          setCurrentIndex(prev => prev + 1);
        };
      }
    } catch {
      showError('L·ªói ph√°t audio');
      setIsAiSpeaking(false);
    }
  }, [script, currentIndex]);

  /**
   * Auto-play mode (Improvement #6)
   * T·ª± ƒë·ªông ƒë·ªçc c√¢u ti·∫øp theo khi AI ho√†n th√†nh
   */
  useEffect(() => {
    if (
      autoPlay &&
      script &&
      !isComplete &&
      !isAiSpeaking &&
      !isRecording &&
      !isProcessing &&
      currentIndex < script.length &&
      !script[currentIndex]?.isUserTurn
    ) {
      const timer = setTimeout(() => {
        speakCurrentLine();
      }, 500); // Delay nh·ªè ƒë·ªÉ t·ª± nhi√™n h∆°n
      return () => clearTimeout(timer);
    }
  }, [autoPlay, script, isComplete, isAiSpeaking, isRecording, isProcessing, currentIndex, speakCurrentLine]);

  /**
   * Hands-only mode (Improvement #7)
   * T·ª± ƒë·ªông skip user turn khi b·∫≠t ch·∫ø ƒë·ªô ch·ªâ nghe
   */
  const skipUserTurn = useCallback(async () => {
    if (!script) return;
    
    // AI ti·∫øp t·ª•c thay v√¨ user n√≥i
    setConversationHistory(prev => [...prev, { speaker: 'YOU', text: '(B·ªè qua l∆∞·ª£t n√≥i)' }]);
    setCurrentIndex(prev => prev + 1);
    
    // Ki·ªÉm tra n·∫øu ƒë√£ h·∫øt script
    if (currentIndex + 1 >= script.length) {
      setIsComplete(true);
    }
  }, [script, currentIndex]);

  useEffect(() => {
    const currentLine = script?.[currentIndex];
    if (
      handsOnlyMode &&
      currentLine?.isUserTurn &&
      !isComplete &&
      !isRecording &&
      !isProcessing
    ) {
      const timer = setTimeout(() => {
        skipUserTurn();
      }, 1000); // Delay l√¢u h∆°n ƒë·ªÉ user ƒë·ªçc g·ª£i √Ω
      return () => clearTimeout(timer);
    }
  }, [handsOnlyMode, script, currentIndex, isComplete, isRecording, isProcessing, skipUserTurn]);

  /**
   * B·∫Øt ƒë·∫ßu ghi √¢m user
   */
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      const chunks: BlobPart[] = [];
      mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach((track) => track.stop());
        const blob = new Blob(chunks, { type: 'audio/webm' });
        await processUserInput(blob);
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch {
      showError('Kh√¥ng th·ªÉ truy c·∫≠p microphone');
    }
  };

  /**
   * D·ª´ng ghi √¢m
   */
  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  /**
   * X·ª≠ l√Ω input c·ªßa user: transcribe v√† AI ti·∫øp t·ª•c
   */
  const processUserInput = async (audioBlob: Blob) => {
    setIsProcessing(true);

    try {
      // 1. Transcribe
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const transcribeRes = await api('/ai/transcribe', {
        method: 'POST',
        body: formData,
      });

      if (!transcribeRes.ok) throw new Error('L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i');
      const { text: userInput } = await transcribeRes.json();

      // Th√™m c√¢u user v√†o history
      setConversationHistory(prev => [...prev, { speaker: 'YOU', text: userInput }]);

      // 2. AI ti·∫øp t·ª•c h·ªôi tho·∫°i
      const continueRes = await api('/ai/continue-conversation', {
        method: 'POST',
        body: JSON.stringify({
          conversationHistory: [...conversationHistory, { speaker: 'YOU', text: userInput }],
          userInput,
          topic,
        }),
      });

      if (!continueRes.ok) throw new Error('L·ªói AI ph·∫£n h·ªìi');
      const { response, shouldEnd } = await continueRes.json();

      // Th√™m ph·∫£n h·ªìi AI
      setConversationHistory(prev => [...prev, { speaker: 'AI Partner', text: response }]);

      // ƒê·ªçc ph·∫£n h·ªìi AI b·∫±ng TTS
      await speakAiResponse(response);

      if (shouldEnd) {
        setIsComplete(true);
      } else {
        setCurrentIndex(prev => prev + 1);
      }
    } catch (err) {
      showError(err instanceof Error ? err.message : 'L·ªói x·ª≠ l√Ω');
    } finally {
      setIsProcessing(false);
    }
  };

  /**
   * AI ƒë·ªçc ph·∫£n h·ªìi
   */
  const speakAiResponse = async (text: string) => {
    setIsAiSpeaking(true);

    try {
      const response = await api('/ai/text-to-speech', {
        method: 'POST',
        body: JSON.stringify({ text, voice: 'nova' }),
      });

      if (!response.ok) return;

      const data = await response.json();
      const audioDataUrl = `data:audio/mpeg;base64,${data.audio}`;

      if (audioRef.current) {
        audioRef.current.src = audioDataUrl;
        audioRef.current.play();
        audioRef.current.onended = () => setIsAiSpeaking(false);
      }
    } catch {
      setIsAiSpeaking(false);
    }
  };

  const currentLine = script?.[currentIndex];
  const isUserTurn = currentLine?.isUserTurn && !isRecording && !isProcessing && !isAiSpeaking;

  return (
    <div className="space-y-6">
      {/* Hidden audio element */}
      <audio ref={audioRef} />

      {/* Header with topic and progress (Improvement #4) */}
      <div className="flex items-center justify-between">
        <div>
          <h3 className="font-display font-semibold text-lg">{topic}</h3>
          <p className="text-sm text-muted-foreground">
            Tham gia h·ªôi tho·∫°i ‚Ä¢ {conversationHistory.length} l∆∞·ª£t
          </p>
        </div>
        {script && !isComplete && (
          <Badge variant="outline" className="text-sm">
            {currentIndex + 1}/{script.length}
          </Badge>
        )}
        {isGenerating && (
          <Badge variant="secondary" className="animate-pulse">
            ƒêang t·∫°o...
          </Badge>
        )}
      </div>

      {/* Settings toggles (Improvement #6, #7) */}
      <div className="flex items-center gap-6 p-3 rounded-lg bg-muted/50">
        <div className="flex items-center gap-2">
          <Switch 
            id="autoPlay" 
            checked={autoPlay} 
            onCheckedChange={setAutoPlay}
          />
          <Label htmlFor="autoPlay" className="text-sm cursor-pointer">
            T·ª± ƒë·ªông ph√°t
          </Label>
        </div>
        <div className="flex items-center gap-2">
          <Switch 
            id="handsOnlyMode" 
            checked={handsOnlyMode} 
            onCheckedChange={setHandsOnlyMode}
          />
          <Label htmlFor="handsOnlyMode" className="text-sm cursor-pointer">
            Ch·ªâ nghe (kh√¥ng n√≥i)
          </Label>
        </div>
      </div>

      {/* Scenario - Enhanced (Improvement #4) */}
      {scenario && (
        <Card className="p-6 bg-primary/10 border-l-4 border-primary">
          <p className="text-sm font-medium text-primary mb-2">üìç T√¨nh hu·ªëng</p>
          <p className="text-lg">{scenario}</p>
        </Card>
      )}

      {/* Conversation history */}
      <div className="space-y-3 max-h-[400px] overflow-y-auto">
        {conversationHistory.map((line, index) => (

          <div
            key={index}
            className={`p-4 rounded-lg ${
              line.speaker === 'YOU'
                ? 'bg-primary/20 ml-8'
                : 'bg-muted mr-8'
            }`}
          >
            <span className={`text-xs font-bold px-2 py-0.5 rounded-full ${
              line.speaker === 'YOU' ? 'bg-primary text-primary-foreground' : 'bg-accent'
            }`}>
              {line.speaker}
            </span>
            <p className="mt-2">{line.text}</p>
          </div>
        ))}

        {/* Current prompt for user */}
        {currentLine?.isUserTurn && !isComplete && (
          <div className="p-4 rounded-lg bg-yellow-100 dark:bg-yellow-900/30 ml-8 animate-pulse">
            <span className="text-xs font-bold px-2 py-0.5 rounded-full bg-yellow-500 text-white">
              üé§ L∆Ø·ª¢T C·ª¶A B·∫†N
            </span>
            <p className="mt-2 text-muted-foreground italic">{currentLine.text}</p>
          </div>
        )}
      </div>

      {/* Controls */}
      <div className="flex gap-3 flex-wrap">
        {!script && (
          <Button onClick={generateScript} disabled={isGenerating}>
            {isGenerating ? '‚è≥ ƒêang t·∫°o...' : 'üé¨ B·∫Øt ƒë·∫ßu h·ªôi tho·∫°i'}
          </Button>
        )}

        {script && !isComplete && !currentLine?.isUserTurn && !isAiSpeaking && (
          <Button onClick={speakCurrentLine}>
            ‚ñ∂Ô∏è Ti·∫øp t·ª•c
          </Button>
        )}

        {isUserTurn && !isRecording && (
          <Button onClick={startRecording} variant="default">
            üéôÔ∏è N√≥i
          </Button>
        )}

        {isRecording && (
          <Button onClick={stopRecording} variant="destructive">
            ‚èπÔ∏è D·ª´ng ghi √¢m
          </Button>
        )}

        {isProcessing && (
          <Button disabled>
            ‚è≥ ƒêang x·ª≠ l√Ω...
          </Button>
        )}

        {isAiSpeaking && (
          <Button disabled variant="outline">
            üîä AI ƒëang n√≥i...
          </Button>
        )}

        <Button variant="outline" onClick={onBack}>
          ‚Üê Quay l·∫°i
        </Button>
      </div>

      {/* Completion message */}
      {isComplete && (
        <Card className="p-6 text-center bg-green-100 dark:bg-green-900/30">
          <p className="text-2xl mb-2">üéâ Ho√†n th√†nh!</p>
          <p className="text-muted-foreground">B·∫°n ƒë√£ ho√†n th√†nh cu·ªôc h·ªôi tho·∫°i</p>
          <Button onClick={generateScript} className="mt-4">
            üîÑ Th·ª≠ l·∫°i
          </Button>
        </Card>
      )}
    </div>
  );
}
