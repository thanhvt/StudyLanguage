import React, {useCallback, useEffect, useRef, useState} from 'react';
import {
  View,
  Pressable,
  ActivityIndicator,
  Animated,
  Platform,
} from 'react-native';
import {SafeAreaView} from 'react-native-safe-area-context';
import {useNavigation} from '@react-navigation/native';
import {AppText} from '@/components/ui';
import AppButton from '@/components/ui/AppButton';
import {useColors} from '@/hooks/useColors';
import {useSpeakingStore} from '@/store/useSpeakingStore';
import {speakingApi} from '@/services/api/speaking';
import {SKILL_COLORS} from '@/config/skillColors';
import Icon from '@/components/ui/Icon';

// Khai b√°o type cho optional native modules
// S·∫Ω ho·∫°t ƒë·ªông khi install react-native-audio-recorder-player
let AudioRecorderPlayerModule: any;
let RNFSModule: any;
try {
  AudioRecorderPlayerModule = require('react-native-audio-recorder-player').default;
} catch {
  console.warn('‚ö†Ô∏è [Speaking] react-native-audio-recorder-player ch∆∞a install');
}
try {
  RNFSModule = require('react-native-fs');
} catch {
  console.warn('‚ö†Ô∏è [Speaking] react-native-fs ch∆∞a install');
}

// =======================
// Constants
// =======================

const MAX_RECORD_SECONDS = 15;
const speakingColor = SKILL_COLORS.speaking.dark;

// =======================
// Audio Recorder
// =======================

const audioRecorderPlayer = AudioRecorderPlayerModule ? new AudioRecorderPlayerModule() : null;

/**
 * M·ª•c ƒë√≠ch: M√†n h√¨nh luy·ªán ph√°t √¢m ch√≠nh ‚Äî hi·ªÉn th·ªã c√¢u + hold-to-record
 * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
 * Tham s·ªë ƒë·∫ßu ra: JSX.Element
 * Khi n√†o s·ª≠ d·ª•ng:
 *   ConfigScreen ‚Üí sinh c√¢u th√†nh c√¥ng ‚Üí navigate Practice
 *   Flow: Xem c√¢u ‚Üí nghe AI m·∫´u ‚Üí gi·ªØ n√∫t mic ‚Üí n√≥i ‚Üí th·∫£ ‚Üí AI ch·∫•m ‚Üí navigate Feedback
 */
export default function PracticeScreen() {
  const navigation = useNavigation<any>();
  const colors = useColors();

  // Store
  const {
    sentences,
    currentIndex,
    isRecording,
    recordingDuration,
    isTranscribing,
    isFeedbackLoading,
    error,
    startRecording,
    stopRecording,
    setRecordingDuration,
    setTranscribing,
    setFeedbackLoading,
    setFeedback,
    setError,
  } = useSpeakingStore();

  const currentSentence = sentences[currentIndex];
  const progress = `${currentIndex + 1} / ${sentences.length}`;

  // Animation
  const pulseAnim = useRef(new Animated.Value(1)).current;
  const [isPlayingAI, setIsPlayingAI] = useState(false);
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // Pulsing animation khi ghi √¢m
  useEffect(() => {
    if (isRecording) {
      const loop = Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {
            toValue: 1.15,
            duration: 600,
            useNativeDriver: true,
          }),
          Animated.timing(pulseAnim, {
            toValue: 1,
            duration: 600,
            useNativeDriver: true,
          }),
        ]),
      );
      loop.start();
      return () => loop.stop();
    } else {
      pulseAnim.setValue(1);
    }
  }, [isRecording, pulseAnim]);

  /**
   * M·ª•c ƒë√≠ch: B·∫Øt ƒë·∫ßu ghi √¢m khi user nh·∫•n gi·ªØ n√∫t mic
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: onPressIn tr√™n n√∫t mic
   */
  const handlePressIn = useCallback(async () => {
    try {
      setError(null);
      startRecording();

      const path = Platform.select({
        ios: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/speaking_record.m4a`,
        android: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/speaking_record.mp4`,
      })!;

      await audioRecorderPlayer?.startRecorder(path);
      console.log('üéôÔ∏è [Practice] B·∫Øt ƒë·∫ßu ghi √¢m t·∫°i:', path);

      // Timer ƒë·∫øm gi√¢y
      let seconds = 0;
      timerRef.current = setInterval(() => {
        seconds += 1;
        setRecordingDuration(seconds);
        if (seconds >= MAX_RECORD_SECONDS) {
          handlePressOut();
        }
      }, 1000);
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói b·∫Øt ƒë·∫ßu ghi √¢m:', err);
      setError('Kh√¥ng th·ªÉ truy c·∫≠p microphone');
      stopRecording('');
    }
  }, [startRecording, setRecordingDuration, setError, stopRecording]);

  /**
   * M·ª•c ƒë√≠ch: D·ª´ng ghi √¢m + g·ª≠i transcribe + evaluate
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: onPressOut tr√™n n√∫t mic ho·∫∑c khi ƒë·∫°t max time
   */
  const handlePressOut = useCallback(async () => {
    try {
      // X√≥a timer
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }

      const audioUri = await audioRecorderPlayer?.stopRecorder() || '';
      stopRecording(audioUri);
      console.log('‚èπÔ∏è [Practice] D·ª´ng ghi √¢m:', audioUri);

      if (!audioUri || recordingDuration < 1) {
        setError('Ghi √¢m qu√° ng·∫Øn, h√£y th·ª≠ l·∫°i');
        return;
      }

      // B∆∞·ªõc 1: Transcribe audio ‚Üí text
      setTranscribing(true);
      console.log('üîÑ [Practice] ƒêang transcribe...');
      const userTranscript = await speakingApi.transcribeAudio(audioUri);
      setTranscribing(false);

      if (!userTranscript.trim()) {
        setError('Kh√¥ng nghe ƒë∆∞·ª£c g√¨, th·ª≠ n√≥i to h∆°n nh√©!');
        return;
      }

      // B∆∞·ªõc 2: Evaluate pronunciation
      setFeedbackLoading(true);
      console.log('üîÑ [Practice] ƒêang ƒë√°nh gi√° ph√°t √¢m...');
      const result = await speakingApi.evaluatePronunciation(
        currentSentence.text,
        userTranscript,
      );
      setFeedback(result);
      console.log('‚úÖ [Practice] ƒê√°nh gi√° xong! ƒêi·ªÉm:', result.overallScore);

      // Navigate qua Feedback
      navigation.navigate('Feedback');
    } catch (err: any) {
      console.error('‚ùå [Practice] L·ªói x·ª≠ l√Ω:', err);
      setTranscribing(false);
      setFeedbackLoading(false);
      setError(err?.message || 'L·ªói x·ª≠ l√Ω ghi √¢m');
    }
  }, [
    stopRecording,
    recordingDuration,
    setTranscribing,
    setFeedbackLoading,
    setFeedback,
    setError,
    currentSentence,
    navigation,
  ]);

  /**
   * M·ª•c ƒë√≠ch: Ph√°t audio m·∫´u t·ª´ AI TTS
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t üîä "Nghe m·∫´u"
   */
  const handlePlayAISample = useCallback(async () => {
    if (isPlayingAI) return;
    try {
      setIsPlayingAI(true);
      console.log('üîä [Practice] Ph√°t audio m·∫´u...');
      const base64Audio = await speakingApi.playAISample(currentSentence.text);

      // L∆∞u base64 ‚Üí file ‚Üí ph√°t
      const tempPath = `${RNFSModule?.CachesDirectoryPath || '/tmp'}/ai_sample.mp3`;
      await RNFSModule?.writeFile(tempPath, base64Audio, 'base64');
      await audioRecorderPlayer?.startPlayer(tempPath);

      audioRecorderPlayer?.addPlayBackListener((e: any) => {
        if (e.currentPosition >= e.duration) {
          audioRecorderPlayer?.stopPlayer();
          audioRecorderPlayer?.removePlayBackListener();
          setIsPlayingAI(false);
        }
      });
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói ph√°t m·∫´u:', err);
      setIsPlayingAI(false);
    }
  }, [isPlayingAI, currentSentence]);

  // Tr·∫°ng th√°i ƒëang x·ª≠ l√Ω
  const isProcessing = isTranscribing || isFeedbackLoading;

  // Format timer
  const formatTime = (s: number) =>
    `${Math.floor(s / 60)}:${String(s % 60).padStart(2, '0')}`;

  if (!currentSentence) {
    return (
      <SafeAreaView className="flex-1 bg-background items-center justify-center">
        <AppText variant="body" raw>
          Kh√¥ng c√≥ c√¢u n√†o ƒë·ªÉ luy·ªán. Vui l√≤ng quay l·∫°i.
        </AppText>
        <AppButton variant="outline" className="mt-4" onPress={() => navigation.goBack()}>
          Quay l·∫°i
        </AppButton>
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView className="flex-1 bg-background">
      {/* Header */}
      <View className="flex-row items-center px-4 pt-2 pb-3">
        <AppButton
          variant="ghost"
          size="icon"
          onPress={() => navigation.goBack()}
          icon={<Icon name="ArrowLeft" className="w-5 h-5 text-foreground" />}
        >
          {''}
        </AppButton>
        <View className="flex-1 items-center">
          <AppText variant="bodySmall" weight="semibold" className="text-foreground" raw>
            {progress}
          </AppText>
        </View>
        <View className="w-9" />
      </View>

      {/* Progress bar */}
      <View className="mx-4 mb-6">
        <View className="h-1 rounded-full bg-neutrals200 overflow-hidden">
          <View
            className="h-1 rounded-full"
            style={{
              width: `${((currentIndex + 1) / sentences.length) * 100}%`,
              backgroundColor: speakingColor,
            }}
          />
        </View>
      </View>

      {/* N·ªôi dung ch√≠nh */}
      <View className="flex-1 px-6 justify-center">
        {/* C√¢u practice */}
        <View className="items-center mb-8">
          <AppText
            variant="heading2"
            weight="semibold"
            className="text-center text-foreground leading-9"
            raw
          >
            {currentSentence.text}
          </AppText>

          {/* IPA (n·∫øu c√≥) */}
          {currentSentence.ipa && (
            <AppText
              variant="bodySmall"
              className="mt-2 text-neutrals400 text-center"
              raw
            >
              {currentSentence.ipa}
            </AppText>
          )}
        </View>

        {/* N√∫t nghe m·∫´u */}
        <View className="items-center mb-10">
          <AppButton
            variant="outline"
            size="sm"
            onPress={handlePlayAISample}
            disabled={isPlayingAI}
            icon={<Icon name="Volume2" className="w-4 h-4 text-foreground" />}
          >
            {isPlayingAI ? 'ƒêang ph√°t...' : 'Nghe m·∫´u'}
          </AppButton>
        </View>
      </View>

      {/* Khu v·ª±c ghi √¢m (bottom) */}
      <View className="items-center pb-8 px-6">
        {/* Tr·∫°ng th√°i x·ª≠ l√Ω */}
        {isProcessing && (
          <View className="flex-row items-center mb-4">
            <ActivityIndicator size="small" color={speakingColor} />
            <AppText variant="bodySmall" className="ml-2 text-neutrals400" raw>
              {isTranscribing ? 'ƒêang nh·∫≠n di·ªán gi·ªçng n√≥i...' : 'ƒêang ƒë√°nh gi√° ph√°t √¢m...'}
            </AppText>
          </View>
        )}

        {/* Error */}
        {error && (
          <View className="mb-4 px-4 py-2 rounded-xl bg-red-500/10">
            <AppText variant="bodySmall" className="text-red-400 text-center" raw>
              {error}
            </AppText>
          </View>
        )}

        {/* Timer khi ghi √¢m */}
        {isRecording && (
          <View className="mb-4 items-center">
            <AppText
              variant="heading3"
              weight="bold"
              className="text-foreground"
              raw
            >
              {formatTime(recordingDuration)}
            </AppText>
            <AppText variant="bodySmall" className="text-neutrals400" raw>
              Th·∫£ ƒë·ªÉ k·∫øt th√∫c
            </AppText>
          </View>
        )}

        {/* N√∫t MIC - hold to record */}
        <Animated.View style={{transform: [{scale: pulseAnim}]}}>
          <Pressable
            onPressIn={handlePressIn}
            onPressOut={handlePressOut}
            disabled={isProcessing}
            style={({pressed}) => ({
              width: 80,
              height: 80,
              borderRadius: 40,
              backgroundColor: isRecording
                ? '#ef4444'
                : pressed
                  ? `${speakingColor}DD`
                  : speakingColor,
              alignItems: 'center',
              justifyContent: 'center',
              opacity: isProcessing ? 0.5 : 1,
              // Shadow
              shadowColor: isRecording ? '#ef4444' : speakingColor,
              shadowOffset: {width: 0, height: 4},
              shadowOpacity: 0.4,
              shadowRadius: 12,
              elevation: 8,
            })}
          >
            <Icon
              name={isRecording ? 'MicOff' : 'Mic'}
              className="w-8 h-8 text-white"
            />
          </Pressable>
        </Animated.View>

        {/* H∆∞·ªõng d·∫´n */}
        {!isRecording && !isProcessing && (
          <AppText
            variant="bodySmall"
            className="mt-4 text-neutrals400 text-center"
            raw
          >
            Gi·ªØ n√∫t mic v√† ƒë·ªçc to, r√µ r√†ng
          </AppText>
        )}
      </View>
    </SafeAreaView>
  );
}
