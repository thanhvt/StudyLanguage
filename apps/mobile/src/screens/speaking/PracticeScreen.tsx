import React, {useCallback, useEffect, useRef, useState} from 'react';
import {
  View,
  Pressable,
  ActivityIndicator,
  Animated,
  Platform,
  TouchableOpacity,
} from 'react-native';
import {SafeAreaView} from 'react-native-safe-area-context';
import {useNavigation} from '@react-navigation/native';
import {AppText} from '@/components/ui';
import AppButton from '@/components/ui/AppButton';
import {useColors} from '@/hooks/useColors';
import {useSpeakingStore} from '@/store/useSpeakingStore';
import {speakingApi} from '@/services/api/speaking';
import {SKILL_COLORS} from '@/config/skillColors';
import Icon from '@/components/ui/Icon';
import {
  CountdownOverlay,
  RecordingPreview,
  IPAPopup,
  VoiceVisualizer,
} from '@/components/speaking';

// Khai b√°o type cho optional native modules
let AudioRecorderPlayerModule: any;
let RNFSModule: any;
try {
  AudioRecorderPlayerModule = require('react-native-audio-recorder-player').default;
} catch {
  console.warn('‚ö†Ô∏è [Speaking] react-native-audio-recorder-player ch∆∞a install');
}
try {
  RNFSModule = require('react-native-fs');
} catch {
  console.warn('‚ö†Ô∏è [Speaking] react-native-fs ch∆∞a install');
}

// =======================
// Constants
// =======================

const MAX_RECORD_SECONDS = 15;
const speakingColor = SKILL_COLORS.speaking.dark;

// =======================
// Audio Recorder
// =======================

const audioRecorderPlayer = AudioRecorderPlayerModule ? new AudioRecorderPlayerModule() : null;

/**
 * M·ª•c ƒë√≠ch: M√†n h√¨nh luy·ªán ph√°t √¢m ch√≠nh ‚Äî countdown ‚Üí record ‚Üí preview ‚Üí submit
 * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
 * Tham s·ªë ƒë·∫ßu ra: JSX.Element
 * Khi n√†o s·ª≠ d·ª•ng:
 *   ConfigScreen ‚Üí sinh c√¢u th√†nh c√¥ng ‚Üí navigate Practice
 *   Flow: Xem c√¢u ‚Üí countdown 3-2-1 ‚Üí ghi √¢m ‚Üí preview ‚Üí submit ‚Üí Feedback
 */
export default function PracticeScreen() {
  const navigation = useNavigation<any>();
  const colors = useColors();

  // Store
  const {
    sentences,
    currentIndex,
    isRecording,
    recordingDuration,
    audioUri,
    isTranscribing,
    isFeedbackLoading,
    error,
    startRecording,
    stopRecording,
    setRecordingDuration,
    setTranscribing,
    setFeedbackLoading,
    setFeedback,
    setError,
    clearRecording,
  } = useSpeakingStore();

  const currentSentence = sentences[currentIndex];
  const progress = `${currentIndex + 1} / ${sentences.length}`;

  // Animation
  const pulseAnim = useRef(new Animated.Value(1)).current;
  const [isPlayingAI, setIsPlayingAI] = useState(false);
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // Sprint 2: C√°c state m·ªõi
  const [showCountdown, setShowCountdown] = useState(false);
  const [showPreview, setShowPreview] = useState(false);
  const [isPlaybackPreview, setIsPlaybackPreview] = useState(false);
  const [ipaPopup, setIpaPopup] = useState<{visible: boolean; word: string; ipa: string}>({
    visible: false,
    word: '',
    ipa: '',
  });

  // Pulsing animation khi ghi √¢m
  useEffect(() => {
    if (isRecording) {
      const loop = Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {
            toValue: 1.15,
            duration: 600,
            useNativeDriver: true,
          }),
          Animated.timing(pulseAnim, {
            toValue: 1,
            duration: 600,
            useNativeDriver: true,
          }),
        ]),
      );
      loop.start();
      return () => loop.stop();
    } else {
      pulseAnim.setValue(1);
    }
  }, [isRecording, pulseAnim]);

  /**
   * M·ª•c ƒë√≠ch: B·∫Øt ƒë·∫ßu countdown tr∆∞·ªõc khi ghi √¢m
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t mic
   */
  const handleMicPress = useCallback(() => {
    setError(null);
    setShowCountdown(true);
    console.log('üó£Ô∏è [Practice] B·∫Øt ƒë·∫ßu countdown...');
  }, [setError]);

  /**
   * M·ª•c ƒë√≠ch: B·∫Øt ƒë·∫ßu ghi √¢m sau countdown
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: Countdown k·∫øt th√∫c ‚Üí auto-start recording
   */
  const handleCountdownComplete = useCallback(async () => {
    setShowCountdown(false);
    try {
      startRecording();
      const path = Platform.select({
        ios: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/speaking_record.m4a`,
        android: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/speaking_record.mp4`,
      })!;

      await audioRecorderPlayer?.startRecorder(path);
      console.log('üéôÔ∏è [Practice] B·∫Øt ƒë·∫ßu ghi √¢m t·∫°i:', path);

      let seconds = 0;
      timerRef.current = setInterval(() => {
        seconds += 1;
        setRecordingDuration(seconds);
        if (seconds >= MAX_RECORD_SECONDS) {
          handleStopRecording();
        }
      }, 1000);
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói b·∫Øt ƒë·∫ßu ghi √¢m:', err);
      setError('Kh√¥ng th·ªÉ truy c·∫≠p microphone');
      stopRecording('');
    }
  }, [startRecording, setRecordingDuration, setError, stopRecording]);

  /**
   * M·ª•c ƒë√≠ch: D·ª´ng ghi √¢m ‚Üí hi·ªán preview
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t stop ho·∫∑c ƒë·∫°t max time
   */
  const handleStopRecording = useCallback(async () => {
    try {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }

      const uri = await audioRecorderPlayer?.stopRecorder() || '';
      stopRecording(uri);
      console.log('‚èπÔ∏è [Practice] D·ª´ng ghi √¢m:', uri);

      if (uri && recordingDuration >= 1) {
        setShowPreview(true);
      } else {
        setError('Ghi √¢m qu√° ng·∫Øn, h√£y th·ª≠ l·∫°i');
      }
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói d·ª´ng ghi √¢m:', err);
      stopRecording('');
    }
  }, [stopRecording, recordingDuration, setError]);

  /**
   * M·ª•c ƒë√≠ch: Ph√°t l·∫°i recording preview
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n play tr√™n RecordingPreview
   */
  const handlePlaybackPreview = useCallback(async () => {
    if (!audioUri) return;
    try {
      if (isPlaybackPreview) {
        await audioRecorderPlayer?.stopPlayer();
        setIsPlaybackPreview(false);
      } else {
        setIsPlaybackPreview(true);
        await audioRecorderPlayer?.startPlayer(audioUri);
        audioRecorderPlayer?.addPlayBackListener((e: any) => {
          if (e.currentPosition >= e.duration) {
            audioRecorderPlayer?.stopPlayer();
            audioRecorderPlayer?.removePlayBackListener();
            setIsPlaybackPreview(false);
          }
        });
      }
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói ph√°t l·∫°i:', err);
      setIsPlaybackPreview(false);
    }
  }, [audioUri, isPlaybackPreview]);

  /**
   * M·ª•c ƒë√≠ch: Ghi l·∫°i (discard recording hi·ªán t·∫°i)
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n "Ghi l·∫°i" tr√™n RecordingPreview
   */
  const handleReRecord = useCallback(() => {
    setShowPreview(false);
    clearRecording();
    console.log('üîÑ [Practice] Ghi l·∫°i...');
  }, [clearRecording]);

  /**
   * M·ª•c ƒë√≠ch: Submit recording ‚Üí transcribe ‚Üí evaluate ‚Üí navigate Feedback
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n "G·ª≠i" tr√™n RecordingPreview
   */
  const handleSubmitRecording = useCallback(async () => {
    if (!audioUri) return;

    try {
      setShowPreview(false);

      // B∆∞·ªõc 1: Transcribe
      setTranscribing(true);
      console.log('üîÑ [Practice] ƒêang transcribe...');
      const userTranscript = await speakingApi.transcribeAudio(audioUri);
      setTranscribing(false);

      if (!userTranscript.trim()) {
        setError('Kh√¥ng nghe ƒë∆∞·ª£c g√¨, th·ª≠ n√≥i to h∆°n nh√©!');
        return;
      }

      // B∆∞·ªõc 2: Evaluate
      setFeedbackLoading(true);
      console.log('üîÑ [Practice] ƒêang ƒë√°nh gi√° ph√°t √¢m...');
      const result = await speakingApi.evaluatePronunciation(
        currentSentence.text,
        userTranscript,
      );
      setFeedback(result);
      console.log('‚úÖ [Practice] ƒê√°nh gi√° xong! ƒêi·ªÉm:', result.overallScore);

      navigation.navigate('Feedback');
    } catch (err: any) {
      console.error('‚ùå [Practice] L·ªói x·ª≠ l√Ω:', err);
      setTranscribing(false);
      setFeedbackLoading(false);
      setError(err?.message || 'L·ªói x·ª≠ l√Ω ghi √¢m');
    }
  }, [
    audioUri,
    setTranscribing,
    setFeedbackLoading,
    setFeedback,
    setError,
    currentSentence,
    navigation,
  ]);

  /**
   * M·ª•c ƒë√≠ch: Ph√°t audio m·∫´u t·ª´ AI TTS
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t üîä "Nghe m·∫´u"
   */
  const handlePlayAISample = useCallback(async () => {
    if (isPlayingAI) return;
    try {
      setIsPlayingAI(true);
      console.log('üîä [Practice] Ph√°t audio m·∫´u...');
      const base64Audio = await speakingApi.playAISample(currentSentence.text);

      const tempPath = `${RNFSModule?.CachesDirectoryPath || '/tmp'}/ai_sample.mp3`;
      await RNFSModule?.writeFile(tempPath, base64Audio, 'base64');
      await audioRecorderPlayer?.startPlayer(tempPath);

      audioRecorderPlayer?.addPlayBackListener((e: any) => {
        if (e.currentPosition >= e.duration) {
          audioRecorderPlayer?.stopPlayer();
          audioRecorderPlayer?.removePlayBackListener();
          setIsPlayingAI(false);
        }
      });
    } catch (err) {
      console.error('‚ùå [Practice] L·ªói ph√°t m·∫´u:', err);
      setIsPlayingAI(false);
    }
  }, [isPlayingAI, currentSentence]);

  /**
   * M·ª•c ƒë√≠ch: M·ªü IPA popup khi tap v√†o t·ª´
   * Tham s·ªë ƒë·∫ßu v√†o: word (string)
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User tap v√†o 1 t·ª´ trong c√¢u practice
   */
  const handleWordTap = useCallback((word: string) => {
    setIpaPopup({
      visible: true,
      word,
      ipa: `/${word.toLowerCase()}/`,
    });
  }, []);

  // Tr·∫°ng th√°i ƒëang x·ª≠ l√Ω
  const isProcessing = isTranscribing || isFeedbackLoading;

  // Format timer
  const formatTime = (s: number) =>
    `${Math.floor(s / 60)}:${String(s % 60).padStart(2, '0')}`;

  if (!currentSentence) {
    return (
      <SafeAreaView className="flex-1 bg-background items-center justify-center">
        <AppText variant="body" raw>
          Kh√¥ng c√≥ c√¢u n√†o ƒë·ªÉ luy·ªán. Vui l√≤ng quay l·∫°i.
        </AppText>
        <AppButton variant="outline" className="mt-4" onPress={() => navigation.goBack()}>
          Quay l·∫°i
        </AppButton>
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView className="flex-1 bg-background">
      {/* Countdown Overlay */}
      <CountdownOverlay
        visible={showCountdown}
        from={3}
        onComplete={handleCountdownComplete}
        sentencePreview={currentSentence.text}
      />

      {/* IPA Popup */}
      <IPAPopup
        visible={ipaPopup.visible}
        onClose={() => setIpaPopup(prev => ({...prev, visible: false}))}
        word={ipaPopup.word}
        ipa={ipaPopup.ipa}
        onPlaySample={async (word) => {
          try {
            const audio = await speakingApi.playAISample(word);
            const path = `${RNFSModule?.CachesDirectoryPath || '/tmp'}/ipa_sample.mp3`;
            await RNFSModule?.writeFile(path, audio, 'base64');
            await audioRecorderPlayer?.startPlayer(path);
          } catch (err) {
            console.error('‚ùå L·ªói ph√°t IPA sample:', err);
          }
        }}
      />

      {/* Header */}
      <View className="flex-row items-center px-4 pt-2 pb-3">
        <AppButton
          variant="ghost"
          size="icon"
          onPress={() => navigation.goBack()}
          icon={<Icon name="ArrowLeft" className="w-5 h-5 text-foreground" />}
        >
          {''}
        </AppButton>
        <View className="flex-1 items-center">
          <AppText variant="bodySmall" weight="semibold" className="text-foreground" raw>
            {progress}
          </AppText>
        </View>
        <View className="w-9" />
      </View>

      {/* Progress bar */}
      <View className="mx-4 mb-6">
        <View className="h-1 rounded-full bg-neutrals200 overflow-hidden">
          <View
            className="h-1 rounded-full"
            style={{
              width: `${((currentIndex + 1) / sentences.length) * 100}%`,
              backgroundColor: speakingColor,
            }}
          />
        </View>
      </View>

      {/* N·ªôi dung ch√≠nh */}
      <View className="flex-1 px-6 justify-center">
        {/* C√¢u practice ‚Äî t·ª´ng t·ª´ tap-able ƒë·ªÉ xem IPA */}
        <View className="items-center mb-8">
          <View style={{flexDirection: 'row', flexWrap: 'wrap', justifyContent: 'center'}}>
            {currentSentence.text.split(' ').map((word, i) => (
              <TouchableOpacity
                key={`${word}-${i}`}
                onPress={() => handleWordTap(word)}
                activeOpacity={0.6}>
                <AppText
                  variant="heading2"
                  weight="semibold"
                  className="text-foreground leading-9"
                  style={{marginHorizontal: 3}}
                  raw>
                  {word}
                </AppText>
              </TouchableOpacity>
            ))}
          </View>

          {/* IPA (n·∫øu c√≥) */}
          {currentSentence.ipa && (
            <AppText
              variant="bodySmall"
              className="mt-2 text-neutrals400 text-center"
              raw
            >
              {currentSentence.ipa}
            </AppText>
          )}
        </View>

        {/* N√∫t nghe m·∫´u */}
        <View className="items-center mb-10">
          <AppButton
            variant="outline"
            size="sm"
            onPress={handlePlayAISample}
            disabled={isPlayingAI}
            icon={<Icon name="Volume2" className="w-4 h-4 text-foreground" />}
          >
            {isPlayingAI ? 'ƒêang ph√°t...' : 'Nghe m·∫´u'}
          </AppButton>
        </View>
      </View>

      {/* Khu v·ª±c ghi √¢m (bottom) */}
      <View className="items-center pb-8 px-6">
        {/* Tr·∫°ng th√°i x·ª≠ l√Ω */}
        {isProcessing && (
          <View className="flex-row items-center mb-4">
            <ActivityIndicator size="small" color={speakingColor} />
            <AppText variant="bodySmall" className="ml-2 text-neutrals400" raw>
              {isTranscribing ? 'ƒêang nh·∫≠n di·ªán gi·ªçng n√≥i...' : 'ƒêang ƒë√°nh gi√° ph√°t √¢m...'}
            </AppText>
          </View>
        )}

        {/* Error */}
        {error && (
          <View className="mb-4 px-4 py-2 rounded-xl bg-red-500/10">
            <AppText variant="bodySmall" className="text-red-400 text-center" raw>
              {error}
            </AppText>
          </View>
        )}

        {/* Recording Preview (Sprint 2) */}
        {showPreview && audioUri ? (
          <RecordingPreview
            audioUri={audioUri}
            duration={recordingDuration}
            isPlaying={isPlaybackPreview}
            onPlayback={handlePlaybackPreview}
            onReRecord={handleReRecord}
            onSubmit={handleSubmitRecording}
            isSubmitting={isProcessing}
          />
        ) : (
          <>
            {/* Waveform khi ƒëang ghi √¢m */}
            {isRecording && (
              <View className="mb-4 items-center">
                <VoiceVisualizer isRecording={isRecording} height={40} />
                <AppText
                  variant="heading3"
                  weight="bold"
                  className="text-foreground mt-2"
                  raw>
                  {formatTime(recordingDuration)}
                </AppText>
                <AppText variant="bodySmall" className="text-neutrals400" raw>
                  Nh·∫•n ƒë·ªÉ d·ª´ng
                </AppText>
              </View>
            )}

            {/* N√∫t MIC */}
            <Animated.View style={{transform: [{scale: pulseAnim}]}}>
              <Pressable
                onPress={isRecording ? handleStopRecording : handleMicPress}
                disabled={isProcessing}
                style={({pressed}) => ({
                  width: 80,
                  height: 80,
                  borderRadius: 40,
                  backgroundColor: isRecording
                    ? '#ef4444'
                    : pressed
                      ? `${speakingColor}DD`
                      : speakingColor,
                  alignItems: 'center',
                  justifyContent: 'center',
                  opacity: isProcessing ? 0.5 : 1,
                  shadowColor: isRecording ? '#ef4444' : speakingColor,
                  shadowOffset: {width: 0, height: 4},
                  shadowOpacity: 0.4,
                  shadowRadius: 12,
                  elevation: 8,
                })}
              >
                <Icon
                  name={isRecording ? 'Square' : 'Mic'}
                  className="w-8 h-8 text-white"
                />
              </Pressable>
            </Animated.View>

            {/* H∆∞·ªõng d·∫´n */}
            {!isRecording && !isProcessing && (
              <AppText
                variant="bodySmall"
                className="mt-4 text-neutrals400 text-center"
                raw>
                Nh·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m
              </AppText>
            )}
          </>
        )}
      </View>
    </SafeAreaView>
  );
}
