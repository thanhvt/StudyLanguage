import React, {useCallback, useEffect, useRef, useState} from 'react';
import {View, Pressable, Animated, Platform, ActivityIndicator} from 'react-native';
import {SafeAreaView} from 'react-native-safe-area-context';
import {useNavigation} from '@react-navigation/native';
import {AppText} from '@/components/ui';
import AppButton from '@/components/ui/AppButton';
import Icon from '@/components/ui/Icon';
import {useColors} from '@/hooks/useColors';
import {SKILL_COLORS} from '@/config/skillColors';
import {useSpeakingStore} from '@/store/useSpeakingStore';
import {speakingApi} from '@/services/api/speaking';
import {
  VoiceVisualizer,
  CountdownOverlay,
  WaveformComparison,
  ScoreBreakdown,
  PhonemeHeatmap,
  ConfettiAnimation,
} from '@/components/speaking';

// Khai b√°o optional modules
let AudioRecorderPlayerModule: any;
let RNFSModule: any;
try {
  AudioRecorderPlayerModule = require('react-native-audio-recorder-player').default;
} catch {
  console.warn('‚ö†Ô∏è [Shadowing] react-native-audio-recorder-player ch∆∞a install');
}
try {
  RNFSModule = require('react-native-fs');
} catch {
  console.warn('‚ö†Ô∏è [Shadowing] react-native-fs ch∆∞a install');
}

const speakingColor = SKILL_COLORS.speaking.dark;
const audioRecorderPlayer = AudioRecorderPlayerModule
  ? new AudioRecorderPlayerModule()
  : null;

// =======================
// Types
// =======================

type ShadowPhase = 'listen' | 'countdown' | 'record' | 'result';

/**
 * M·ª•c ƒë√≠ch: Ch·∫ø ƒë·ªô Shadowing ‚Äî nghe AI ‚Üí l·∫∑p l·∫°i ‚Üí so s√°nh waveform + ƒëi·ªÉm
 * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
 * Tham s·ªë ƒë·∫ßu ra: JSX.Element
 * Khi n√†o s·ª≠ d·ª•ng:
 *   ConfigScreen ‚Üí navigate Shadowing
 *   Flow: Nghe AI ‚Üí Countdown ‚Üí Ghi √¢m ‚Üí So s√°nh k·∫øt qu·∫£
 */
export default function ShadowingScreen() {
  const navigation = useNavigation<any>();
  const colors = useColors();
  const {sentences, currentIndex, nextSentence, clearRecording} = useSpeakingStore();

  const currentSentence = sentences[currentIndex];
  const progress = `${currentIndex + 1} / ${sentences.length}`;

  // State ch√≠nh
  const [phase, setPhase] = useState<ShadowPhase>('listen');
  const [isPlayingAI, setIsPlayingAI] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordDuration, setRecordDuration] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  const [showConfetti, setShowConfetti] = useState(false);

  // K·∫øt qu·∫£
  const [result, setResult] = useState<{
    overallScore: number;
    scores: {label: string; value: number; icon: string}[];
    wordByWord: {word: string; score: number; issue?: string}[];
  } | null>(null);

  // Waveform data (gi·∫£ l·∫≠p ‚Äî trong th·ª±c t·∫ø s·∫Ω l·∫•y t·ª´ audio analysis)
  const [aiWaveform] = useState(() =>
    Array.from({length: 40}, () => 0.2 + Math.random() * 0.8),
  );
  const [userWaveform, setUserWaveform] = useState<number[]>([]);

  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const pulseAnim = useRef(new Animated.Value(1)).current;

  // Pulse animation cho mic
  useEffect(() => {
    if (isRecording) {
      const loop = Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {toValue: 1.15, duration: 500, useNativeDriver: true}),
          Animated.timing(pulseAnim, {toValue: 1, duration: 500, useNativeDriver: true}),
        ]),
      );
      loop.start();
      return () => loop.stop();
    }
    pulseAnim.setValue(1);
  }, [isRecording, pulseAnim]);

  /**
   * M·ª•c ƒë√≠ch: Ph√°t audio AI m·∫´u
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: Phase "listen" ‚Äî user nh·∫•n play
   */
  const handlePlayAI = useCallback(async () => {
    if (isPlayingAI || !currentSentence) return;
    try {
      setIsPlayingAI(true);
      console.log('üîä [Shadowing] Ph√°t AI m·∫´u...');
      const base64 = await speakingApi.playAISample(currentSentence.text);
      const path = `${RNFSModule?.CachesDirectoryPath || '/tmp'}/shadow_ai.mp3`;
      await RNFSModule?.writeFile(path, base64, 'base64');
      await audioRecorderPlayer?.startPlayer(path);

      audioRecorderPlayer?.addPlayBackListener((e: any) => {
        if (e.currentPosition >= e.duration) {
          audioRecorderPlayer?.stopPlayer();
          audioRecorderPlayer?.removePlayBackListener();
          setIsPlayingAI(false);
        }
      });
    } catch (err) {
      console.error('‚ùå [Shadowing] L·ªói ph√°t m·∫´u:', err);
      setIsPlayingAI(false);
    }
  }, [isPlayingAI, currentSentence]);

  /**
   * M·ª•c ƒë√≠ch: Chuy·ªÉn sang phase countdown ‚Üí record
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n "B·∫Øt ƒë·∫ßu l·∫∑p l·∫°i"
   */
  const handleStartShadow = useCallback(() => {
    setPhase('countdown');
    console.log('‚è±Ô∏è [Shadowing] B·∫Øt ƒë·∫ßu countdown...');
  }, []);

  /**
   * M·ª•c ƒë√≠ch: B·∫Øt ƒë·∫ßu ghi √¢m sau countdown
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: Countdown ho√†n t·∫•t
   */
  const handleCountdownDone = useCallback(async () => {
    setPhase('record');
    setIsRecording(true);
    setRecordDuration(0);

    try {
      const path = Platform.select({
        ios: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/shadow_record.m4a`,
        android: `${RNFSModule?.CachesDirectoryPath || '/tmp'}/shadow_record.mp4`,
      })!;
      await audioRecorderPlayer?.startRecorder(path);
      console.log('üéôÔ∏è [Shadowing] Ghi √¢m b·∫Øt ƒë·∫ßu');

      let secs = 0;
      timerRef.current = setInterval(() => {
        secs += 1;
        setRecordDuration(secs);
        if (secs >= 15) {
          handleStopRecord();
        }
      }, 1000);
    } catch (err) {
      console.error('‚ùå [Shadowing] L·ªói ghi √¢m:', err);
      setIsRecording(false);
      setPhase('listen');
    }
  }, []);

  /**
   * M·ª•c ƒë√≠ch: D·ª´ng ghi √¢m ‚Üí evaluate ‚Üí hi·ªán k·∫øt qu·∫£
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n stop ho·∫∑c h·∫øt 15s
   */
  const handleStopRecord = useCallback(async () => {
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    try {
      const uri = (await audioRecorderPlayer?.stopRecorder()) || '';
      setIsRecording(false);
      setIsProcessing(true);
      console.log('‚èπÔ∏è [Shadowing] D·ª´ng ghi √¢m, ƒëang x·ª≠ l√Ω...');

      // T·∫°o waveform gi·∫£ cho user
      setUserWaveform(Array.from({length: 40}, () => 0.2 + Math.random() * 0.8));

      // Transcribe + Evaluate
      const transcript = await speakingApi.transcribeAudio(uri);
      const evalResult = await speakingApi.evaluatePronunciation(
        currentSentence.text,
        transcript,
      );

      setResult({
        overallScore: evalResult.overallScore,
        scores: [
          {label: 'Ph√°t √¢m', value: evalResult.pronunciation, icon: 'üéØ'},
          {label: 'Tr√¥i ch·∫£y', value: evalResult.fluency, icon: 'üí¨'},
          {label: 'T·ªëc ƒë·ªô', value: evalResult.pace, icon: '‚ö°'},
        ],
        wordByWord: evalResult.wordByWord,
      });

      if (evalResult.overallScore >= 80) {
        setShowConfetti(true);
        setTimeout(() => setShowConfetti(false), 3500);
      }

      setPhase('result');
      console.log('‚úÖ [Shadowing] K·∫øt qu·∫£:', evalResult.overallScore);
    } catch (err: any) {
      console.error('‚ùå [Shadowing] L·ªói x·ª≠ l√Ω:', err);
      setPhase('listen');
    } finally {
      setIsProcessing(false);
    }
  }, [currentSentence]);

  /**
   * M·ª•c ƒë√≠ch: Th·ª≠ l·∫°i c√πng c√¢u
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n "Th·ª≠ l·∫°i"
   */
  const handleRetry = useCallback(() => {
    setPhase('listen');
    setResult(null);
    clearRecording();
  }, [clearRecording]);

  /**
   * M·ª•c ƒë√≠ch: Chuy·ªÉn sang c√¢u ti·∫øp
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n "C√¢u ti·∫øp"
   */
  const handleNext = useCallback(() => {
    nextSentence();
    clearRecording();
    setPhase('listen');
    setResult(null);
  }, [nextSentence, clearRecording]);

  const formatTime = (s: number) =>
    `${Math.floor(s / 60)}:${String(s % 60).padStart(2, '0')}`;

  if (!currentSentence) {
    return (
      <SafeAreaView className="flex-1 bg-background items-center justify-center">
        <AppText variant="body" raw>Kh√¥ng c√≥ c√¢u. Vui l√≤ng quay l·∫°i.</AppText>
        <AppButton variant="outline" className="mt-4" onPress={() => navigation.goBack()}>
          Quay l·∫°i
        </AppButton>
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView className="flex-1 bg-background">
      {/* Confetti */}
      <ConfettiAnimation visible={showConfetti} />

      {/* Countdown */}
      <CountdownOverlay
        visible={phase === 'countdown'}
        from={3}
        onComplete={handleCountdownDone}
        sentencePreview={currentSentence.text}
      />

      {/* Header */}
      <View className="flex-row items-center px-4 pt-2 pb-3">
        <AppButton
          variant="ghost" size="icon"
          onPress={() => navigation.goBack()}
          icon={<Icon name="ArrowLeft" className="w-5 h-5 text-foreground" />}>
          {''}
        </AppButton>
        <View className="flex-1 items-center">
          <AppText variant="heading3" weight="bold">üéß Shadowing</AppText>
          <AppText variant="caption" className="text-neutrals400">{progress}</AppText>
        </View>
        <View className="w-9" />
      </View>

      {/* Progress bar */}
      <View className="mx-4 mb-4">
        <View className="h-1 rounded-full bg-neutrals200 overflow-hidden">
          <View
            className="h-1 rounded-full"
            style={{
              width: `${((currentIndex + 1) / sentences.length) * 100}%`,
              backgroundColor: speakingColor,
            }}
          />
        </View>
      </View>

      {/* === PHASE: LISTEN === */}
      {phase === 'listen' && (
        <View className="flex-1 px-6 justify-center items-center">
          <AppText variant="heading2" weight="semibold" className="text-center text-foreground mb-6" raw>
            {currentSentence.text}
          </AppText>
          {currentSentence.ipa && (
            <AppText variant="bodySmall" className="text-neutrals400 mb-8 text-center" raw>
              {currentSentence.ipa}
            </AppText>
          )}

          {/* N√∫t nghe */}
          <AppButton
            variant="outline" size="default"
            onPress={handlePlayAI}
            disabled={isPlayingAI}
            icon={<Icon name="Volume2" className="w-5 h-5 text-foreground" />}>
            {isPlayingAI ? 'ƒêang ph√°t...' : 'üîä Nghe AI m·∫´u'}
          </AppButton>

          <View className="h-8" />

          {/* N√∫t b·∫Øt ƒë·∫ßu shadow */}
          <AppButton
            variant="primary" size="lg"
            style={{backgroundColor: speakingColor}}
            onPress={handleStartShadow}>
            üéôÔ∏è B·∫Øt ƒë·∫ßu l·∫∑p l·∫°i
          </AppButton>
        </View>
      )}

      {/* === PHASE: RECORD === */}
      {phase === 'record' && (
        <View className="flex-1 px-6 justify-center items-center">
          <AppText variant="heading2" weight="semibold" className="text-center text-foreground mb-4" raw>
            {currentSentence.text}
          </AppText>

          <VoiceVisualizer isRecording={isRecording} height={50} color={speakingColor} />

          <AppText variant="heading3" weight="bold" className="text-foreground mt-3" raw>
            {formatTime(recordDuration)}
          </AppText>

          <View className="mt-6">
            <Animated.View style={{transform: [{scale: pulseAnim}]}}>
              <Pressable
                onPress={handleStopRecord}
                style={{
                  width: 72,
                  height: 72,
                  borderRadius: 36,
                  backgroundColor: '#ef4444',
                  alignItems: 'center',
                  justifyContent: 'center',
                  shadowColor: '#ef4444',
                  shadowOffset: {width: 0, height: 4},
                  shadowOpacity: 0.4,
                  shadowRadius: 12,
                }}>
                <Icon name="Square" className="w-7 h-7 text-white" />
              </Pressable>
            </Animated.View>
          </View>

          <AppText variant="bodySmall" className="text-neutrals400 mt-3" raw>
            Nh·∫•n ƒë·ªÉ d·ª´ng ghi √¢m
          </AppText>
        </View>
      )}

      {/* === PROCESSING === */}
      {isProcessing && (
        <View className="flex-1 items-center justify-center">
          <ActivityIndicator size="large" color={speakingColor} />
          <AppText variant="body" className="text-neutrals400 mt-4" raw>
            ƒêang so s√°nh ph√°t √¢m...
          </AppText>
        </View>
      )}

      {/* === PHASE: RESULT === */}
      {phase === 'result' && result && (
        <View className="flex-1">
          <View style={{paddingTop: 16}}>
            {/* Score l·ªõn */}
            <View className="items-center mb-4">
              <AppText variant="heading1" weight="bold" style={{color: speakingColor, fontSize: 52}} raw>
                {result.overallScore}
              </AppText>
              <AppText variant="bodySmall" className="text-neutrals400" raw>/ 100</AppText>
            </View>

            {/* Waveform so s√°nh */}
            <WaveformComparison aiWaveform={aiWaveform} userWaveform={userWaveform} height={70} />

            {/* Score breakdown */}
            <ScoreBreakdown scores={result.scores} />

            {/* Phoneme heatmap */}
            <PhonemeHeatmap words={result.wordByWord} />
          </View>

          {/* Actions */}
          <View className="flex-row gap-3 px-4 pb-4 mt-auto">
            <AppButton variant="outline" size="lg" className="flex-1" onPress={handleRetry}>
              üîÅ Th·ª≠ l·∫°i
            </AppButton>
            <AppButton
              variant="primary" size="lg" className="flex-1"
              style={{backgroundColor: speakingColor}}
              onPress={currentIndex >= sentences.length - 1 ? () => navigation.popToTop() : handleNext}>
              {currentIndex >= sentences.length - 1 ? '‚úÖ Ho√†n th√†nh' : '‚û°Ô∏è C√¢u ti·∫øp'}
            </AppButton>
          </View>
        </View>
      )}
    </SafeAreaView>
  );
}
