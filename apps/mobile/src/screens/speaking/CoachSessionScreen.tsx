import React, {useEffect, useRef, useCallback, useState} from 'react';
import {
  View,
  FlatList,
  TextInput,
  KeyboardAvoidingView,
  Platform,
  TouchableOpacity,
  ActivityIndicator,
  StyleSheet,
  Alert,
} from 'react-native';
import {SafeAreaView} from 'react-native-safe-area-context';
import {useNavigation} from '@react-navigation/native';
import {AppText} from '@/components/ui';
import AppButton from '@/components/ui/AppButton';
import Icon from '@/components/ui/Icon';
import {useColors} from '@/hooks/useColors';
import {useSpeakingStore} from '@/store/useSpeakingStore';
import {speakingApi} from '@/services/api/speaking';
import {SKILL_COLORS} from '@/config/skillColors';
import {
  ChatBubble,
  VoiceVisualizer,
  PronunciationAlert,
  GrammarFix,
  SuggestedResponses,
} from '@/components/speaking';
import type {ChatMessage} from '@/components/speaking/ChatBubble';
import type {PronunciationCorrection} from '@/components/speaking/PronunciationAlert';
import type {GrammarCorrection} from '@/components/speaking/GrammarFix';
import AudioRecorderPlayer from 'react-native-audio-recorder-player';
import {useCoachTrackPlayer} from '@/hooks/useCoachTrackPlayer';

// =======================
// Types
// =======================

/** Item trong FlatList c√≥ th·ªÉ l√† message, pronunciation fix, ho·∫∑c grammar fix */
type ChatItem =
  | {type: 'message'; data: ChatMessage}
  | {type: 'pronunciation'; data: PronunciationCorrection}
  | {type: 'grammar'; data: GrammarCorrection};

// =======================
// Screen
// =======================

/**
 * M·ª•c ƒë√≠ch: M√†n h√¨nh h·ªôi tho·∫°i ch√≠nh v·ªõi AI Coach
 * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng c√≥
 * Tham s·ªë ƒë·∫ßu ra: JSX.Element
 * Khi n√†o s·ª≠ d·ª•ng:
 *   CoachSetupScreen ‚Üí startCoachSession ‚Üí navigate CoachSession
 *   User n√≥i/g√µ text ‚Üí AI tr·∫£ l·ªùi + s·ª≠a l·ªói realtime
 */
export default function CoachSessionScreen() {
  const navigation = useNavigation<any>();
  const colors = useColors();
  const speakingColor = SKILL_COLORS.speaking.dark;

  // Store
  const {
    coachSession,
    isRecording,
    startRecording: storeStartRecording,
    stopRecording: storeStopRecording,
    addCoachMessage,
    setCoachAIResponding,
    tickCoachTimer,
    endCoachSession,
    setError,
    error,
  } = useSpeakingStore();

  // Refs
  const flatListRef = useRef<FlatList>(null);
  const audioRecorder = useRef(new AudioRecorderPlayer()).current;
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // Local state
  const [chatItems, setChatItems] = useState<ChatItem[]>([]);
  const [textInput, setTextInput] = useState('');
  const [playingMessageId, setPlayingMessageId] = useState<string | null>(null);

  // Coach TrackPlayer ‚Äî h·ªó tr·ª£ ph√°t audio AI ·ªü background
  const {playCoachAudio, stopCoach} = useCoachTrackPlayer();

  // Shorthand
  const session = coachSession;
  const inputMode = session?.inputMode || 'voice';
  const isAIResponding = session?.isAIResponding || false;
  const isEnded = session?.isEnded || false;
  const remainingSeconds = session?.remainingSeconds || 0;

  // =======================
  // Timer
  // =======================

  useEffect(() => {
    if (!session || isEnded) return;

    timerRef.current = setInterval(() => {
      tickCoachTimer();
    }, 1000);

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isEnded]);

  // G·ª≠i welcome message khi b·∫Øt ƒë·∫ßu
  useEffect(() => {
    if (session && session.messages.length === 0) {
      sendWelcomeMessage();
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // =======================
  // Helpers
  // =======================

  /**
   * M·ª•c ƒë√≠ch: Format th·ªùi gian t·ª´ seconds ‚Üí mm:ss
   * Tham s·ªë ƒë·∫ßu v√†o: seconds (number)
   * Tham s·ªë ƒë·∫ßu ra: string (mm:ss)
   * Khi n√†o s·ª≠ d·ª•ng: Hi·ªÉn th·ªã timer ·ªü header
   */
  const formatTime = (seconds: number): string => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}:${s.toString().padStart(2, '0')}`;
  };

  /**
   * M·ª•c ƒë√≠ch: T·∫°o unique ID cho message
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: string
   * Khi n√†o s·ª≠ d·ª•ng: Khi t·∫°o ChatMessage m·ªõi
   */
  const generateId = (): string => `msg_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`;

  // =======================
  // AI Communication
  // =======================

  /**
   * M·ª•c ƒë√≠ch: G·ª≠i tin nh·∫Øn ch√†o ƒë·∫ßu ti√™n t·ª´ AI
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: Khi CoachSession m·ªõi b·∫Øt ƒë·∫ßu (messages.length === 0)
   */
  const sendWelcomeMessage = async () => {
    if (!session) return;

    setCoachAIResponding(true);
    try {
      const result = await speakingApi.continueConversation(
        [],
        '',
        session.setup.topic,
      );

      const aiMessage: ChatMessage = {
        id: generateId(),
        role: 'ai',
        text: result.response,
        timestamp: Date.now(),
      };

      addCoachMessage(aiMessage);
      setChatItems(prev => [...prev, {type: 'message', data: aiMessage}]);
    } catch (err) {
      console.error('‚ùå [Coach] L·ªói g·ª≠i welcome:', err);
      const fallback: ChatMessage = {
        id: generateId(),
        role: 'ai',
        text: `Hi there! Let's talk about "${session.setup.topic}". How about you start by sharing your thoughts?`,
        timestamp: Date.now(),
      };
      addCoachMessage(fallback);
      setChatItems(prev => [...prev, {type: 'message', data: fallback}]);
    } finally {
      setCoachAIResponding(false);
    }
  };

  /**
   * M·ª•c ƒë√≠ch: G·ª≠i tin nh·∫Øn user ‚Üí nh·∫≠n ph·∫£n h·ªìi AI + corrections
   * Tham s·ªë ƒë·∫ßu v√†o: text (string) ‚Äî n·ªôi dung user v·ª´a n√≥i/g√µ
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: Sau khi user g√µ text ho·∫∑c ho√†n t·∫•t ghi √¢m ‚Üí transcribe
   */
  const sendUserMessage = async (text: string) => {
    if (!session || !text.trim() || isEnded) return;

    // Th√™m message user
    const userMsg: ChatMessage = {
      id: generateId(),
      role: 'user',
      text: text.trim(),
      timestamp: Date.now(),
    };
    addCoachMessage(userMsg);
    setChatItems(prev => [...prev, {type: 'message', data: userMsg}]);
    setTextInput('');

    // G·ªçi AI
    setCoachAIResponding(true);
    try {
      const history = [...(session.messages || []), userMsg].map(m => ({
        speaker: m.role === 'ai' ? 'assistant' : 'user',
        text: m.text,
      }));

      const result = await speakingApi.continueConversation(
        history,
        text.trim(),
        session.setup.topic,
      );

      // Th√™m grammar corrections (n·∫øu c√≥)
      if (result.corrections && result.corrections.length > 0) {
        const grammarItems: ChatItem[] = result.corrections.map(c => ({
          type: 'grammar' as const,
          data: {
            original: c.original,
            correction: c.correction,
            explanation: c.explanation,
          },
        }));
        setChatItems(prev => [...prev, ...grammarItems]);
      }

      // Th√™m AI response
      const aiMsg: ChatMessage = {
        id: generateId(),
        role: 'ai',
        text: result.response,
        timestamp: Date.now(),
      };
      addCoachMessage(aiMsg);
      setChatItems(prev => [...prev, {type: 'message', data: aiMsg}]);

      // Sinh v√† ph√°t audio AI response qua TrackPlayer (background capable)
      try {
        const {ttsSettings} = useSpeakingStore.getState();
        const audioUrl = await speakingApi.generateCoachAudio(
          result.response,
          ttsSettings.provider,
          ttsSettings.voiceId,
          ttsSettings.speed,
        );
        if (audioUrl) {
          await playCoachAudio(audioUrl);
        }
      } catch (audioErr) {
        console.warn('‚ö†Ô∏è [Coach] Kh√¥ng ph√°t ƒë∆∞·ª£c audio AI:', audioErr);
      }

      // Ki·ªÉm tra k·∫øt th√∫c
      if (result.shouldEnd) {
        endCoachSession();
      }
    } catch (err: any) {
      console.error('‚ùå [Coach] L·ªói g·ª≠i message:', err);
      setError('L·ªói k·∫øt n·ªëi AI Coach. Th·ª≠ l·∫°i nh√©!');
    } finally {
      setCoachAIResponding(false);
    }
  };

  // =======================
  // Recording
  // =======================

  /**
   * M·ª•c ƒë√≠ch: B·∫Øt ƒë·∫ßu ghi √¢m voice
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n gi·ªØ n√∫t mic
   */
  const handleStartRecording = async () => {
    try {
      storeStartRecording();
      const result = await audioRecorder.startRecorder();
      console.log('üéôÔ∏è [Coach] B·∫Øt ƒë·∫ßu ghi √¢m:', result);
    } catch (err) {
      console.error('‚ùå [Coach] L·ªói ghi √¢m:', err);
      storeStopRecording('');
    }
  };

  /**
   * M·ª•c ƒë√≠ch: D·ª´ng ghi √¢m ‚Üí transcribe ‚Üí g·ª≠i message
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User th·∫£ n√∫t mic
   */
  const handleStopRecording = async () => {
    try {
      const audioUri = await audioRecorder.stopRecorder();
      storeStopRecording(audioUri);
      console.log('üéôÔ∏è [Coach] D·ª´ng ghi √¢m:', audioUri);

      // Transcribe ‚Üí g·ª≠i message
      const transcript = await speakingApi.transcribeAudio(audioUri);
      if (transcript.trim()) {
        await sendUserMessage(transcript);
      } else {
        console.log('‚ö†Ô∏è [Coach] Transcript r·ªóng, b·ªè qua');
      }
    } catch (err) {
      console.error('‚ùå [Coach] L·ªói x·ª≠ l√Ω recording:', err);
      storeStopRecording('');
      setError('Kh√¥ng nh·∫≠n ƒë∆∞·ª£c gi·ªçng n√≥i. Th·ª≠ l·∫°i nh√©!');
    }
  };

  /**
   * M·ª•c ƒë√≠ch: G·ª≠i text input khi user g√µ
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t g·ª≠i ·ªü text mode
   */
  const handleSendText = () => {
    if (textInput.trim()) {
      sendUserMessage(textInput);
    }
  };

  /**
   * M·ª•c ƒë√≠ch: Ph√°t audio AI response
   * Tham s·ªë ƒë·∫ßu v√†o: audioUrl (string)
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User tap n√∫t speaker tr√™n AI bubble
   */
  const handlePlayAudio = useCallback(async (audioUrl: string) => {
    try {
      setPlayingMessageId(audioUrl);
      await audioRecorder.startPlayer(audioUrl);
      audioRecorder.addPlayBackListener((e) => {
        if (e.currentPosition >= e.duration) {
          setPlayingMessageId(null);
          audioRecorder.stopPlayer();
        }
      });
    } catch (err) {
      console.error('‚ùå [Coach] L·ªói ph√°t audio:', err);
      setPlayingMessageId(null);
    }
  }, [audioRecorder]);

  /**
   * M·ª•c ƒë√≠ch: X·ª≠ l√Ω khi user ch·ªçn g·ª£i √Ω (beginner mode)
   * Tham s·ªë ƒë·∫ßu v√†o: suggestion (string)
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User tap chip g·ª£i √Ω ‚Üí auto-send
   */
  const handleSelectSuggestion = (suggestion: string) => {
    sendUserMessage(suggestion);
  };

  /**
   * M·ª•c ƒë√≠ch: K·∫øt th√∫c session th·ªß c√¥ng
   * Tham s·ªë ƒë·∫ßu v√†o: kh√¥ng
   * Tham s·ªë ƒë·∫ßu ra: void
   * Khi n√†o s·ª≠ d·ª•ng: User nh·∫•n n√∫t End ho·∫∑c h·∫øt th·ªùi gian
   */
  const handleEndSession = () => {
    Alert.alert(
      'K·∫øt th√∫c bu·ªïi n√≥i chuy·ªán?',
      'B·∫°n c√≥ mu·ªën k·∫øt th√∫c session n√†y kh√¥ng?',
      [
        {text: 'Ti·∫øp t·ª•c', style: 'cancel'},
        {
          text: 'K·∫øt th√∫c',
          style: 'destructive',
          onPress: () => {
            endCoachSession();
          },
        },
      ],
    );
  };

  // =======================
  // Auto-scroll
  // =======================

  useEffect(() => {
    if (chatItems.length > 0 && flatListRef.current) {
      setTimeout(() => {
        flatListRef.current?.scrollToEnd({animated: true});
      }, 100);
    }
  }, [chatItems.length]);

  // =======================
  // Cleanup
  // =======================

  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      audioRecorder.stopRecorder().catch(() => {});
      audioRecorder.stopPlayer().catch(() => {});
      // Cleanup TrackPlayer khi r·ªùi m√†n h√¨nh
      stopCoach();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // =======================
  // Render
  // =======================

  /**
   * M·ª•c ƒë√≠ch: Render 1 item trong FlatList (message, pronunciation, grammar)
   * Tham s·ªë ƒë·∫ßu v√†o: item (ChatItem)
   * Tham s·ªë ƒë·∫ßu ra: JSX.Element
   * Khi n√†o s·ª≠ d·ª•ng: FlatList renderItem callback
   */
  const renderItem = ({item}: {item: ChatItem}) => {
    switch (item.type) {
      case 'message':
        return (
          <ChatBubble
            message={item.data}
            onPlayAudio={handlePlayAudio}
            isPlaying={playingMessageId === item.data.audioUrl}
          />
        );
      case 'pronunciation':
        return (
          <PronunciationAlert
            correction={item.data}
            onPlaySample={async (word: string) => {
              try {
                const audio = await speakingApi.playAISample(word);
                if (audio) {
                  await audioRecorder.startPlayer(audio);
                }
              } catch (err) {
                console.error('‚ùå [Coach] L·ªói ph√°t m·∫´u:', err);
              }
            }}
          />
        );
      case 'grammar':
        return <GrammarFix correction={item.data} />;
      default:
        return null;
    }
  };

  const keyExtractor = (item: ChatItem, index: number) => {
    if (item.type === 'message') return item.data.id;
    return `correction_${index}`;
  };

  // Safety check
  if (!session) {
    return (
      <SafeAreaView className="flex-1 bg-background items-center justify-center">
        <AppText variant="body" className="text-neutrals400" raw>
          Ch∆∞a c√≥ session. Quay l·∫°i setup.
        </AppText>
        <AppButton
          variant="primary"
          size="default"
          className="mt-4"
          onPress={() => navigation.goBack()}>
          ‚Üê Quay l·∫°i
        </AppButton>
      </SafeAreaView>
    );
  }

  return (
    <SafeAreaView className="flex-1 bg-background">
      <KeyboardAvoidingView
        behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
        className="flex-1"
        keyboardVerticalOffset={10}>
        {/* ======= HEADER ======= */}
        <View
          className="flex-row items-center px-4 py-3"
          style={{borderBottomWidth: 0.5, borderBottomColor: colors.border}}>
          <AppButton
            variant="ghost"
            size="icon"
            onPress={() => navigation.goBack()}
            icon={<Icon name="ArrowLeft" className="w-5 h-5 text-foreground" />}>
            {''}
          </AppButton>

          <View className="flex-1 items-center">
            <AppText variant="body" weight="bold" raw>
              ü§ñ {session.setup.topic}
            </AppText>
            <AppText
              variant="caption"
              style={{color: remainingSeconds < 60 ? '#EF4444' : colors.neutrals400}}
              raw>
              ‚è± {formatTime(remainingSeconds)}
            </AppText>
          </View>

          <TouchableOpacity
            onPress={handleEndSession}
            style={[styles.endBtn, {backgroundColor: '#EF444420'}]}>
            <AppText variant="caption" weight="bold" style={{color: '#EF4444'}} raw>
              K·∫øt th√∫c
            </AppText>
          </TouchableOpacity>
        </View>

        {/* ======= CHAT LIST ======= */}
        <FlatList
          ref={flatListRef}
          data={chatItems}
          renderItem={renderItem}
          keyExtractor={keyExtractor}
          contentContainerStyle={styles.chatContent}
          showsVerticalScrollIndicator={false}
          ListEmptyComponent={
            <View className="flex-1 items-center justify-center py-20">
              <ActivityIndicator size="large" color={speakingColor} />
              <AppText
                variant="bodySmall"
                className="text-neutrals400 mt-3"
                raw>
                AI Coach ƒëang chu·∫©n b·ªã...
              </AppText>
            </View>
          }
        />

        {/* Session ended banner */}
        {isEnded && (
          <View style={[styles.endedBanner, {backgroundColor: `${speakingColor}15`}]}>
            <AppText variant="body" weight="semibold" raw>
              üéâ Session k·∫øt th√∫c!
            </AppText>
            <AppText variant="bodySmall" className="text-neutrals400 mt-1" raw>
              B·∫°n ƒë√£ n√≥i {session.messages.filter(m => m.role === 'user').length} l∆∞·ª£t.
            </AppText>
            <AppButton
              variant="primary"
              size="default"
              className="mt-3"
              style={{backgroundColor: speakingColor}}
              onPress={() => navigation.goBack()}>
              ‚Üê Quay l·∫°i
            </AppButton>
          </View>
        )}

        {/* ======= INPUT AREA ======= */}
        {!isEnded && (
          <View style={[styles.inputArea, {borderTopColor: colors.border}]}>
            {/* Error */}
            {error && (
              <AppText
                variant="caption"
                style={{color: '#EF4444', paddingHorizontal: 12, paddingBottom: 4}}
                raw>
                ‚ö†Ô∏è {error}
              </AppText>
            )}

            {/* G·ª£i √Ω (beginner mode) */}
            {session.setup.feedbackMode === 'beginner' && !isRecording && (
              <SuggestedResponses
                suggestions={[
                  'Yes, I agree.',
                  'Could you say that again?',
                  "That's interesting!",
                  "I'm not sure.",
                ]}
                onSelect={handleSelectSuggestion}
                disabled={isAIResponding}
              />
            )}

            {/* Voice Visualizer khi ƒëang thu */}
            {isRecording && (
              <View style={styles.recordingIndicator}>
                <VoiceVisualizer isRecording={isRecording} height={40} />
                <AppText
                  variant="caption"
                  style={{color: speakingColor, marginTop: 4}}
                  raw>
                  ƒêang nghe...
                </AppText>
              </View>
            )}

            {/* Input controls */}
            <View style={styles.inputRow}>
              {/* Toggle voice/text */}
              <TouchableOpacity
                onPress={() => {
                  const newMode = inputMode === 'voice' ? 'text' : 'voice';
                  useSpeakingStore.getState().setCoachInputMode(newMode);
                }}
                style={[styles.toggleBtn, {backgroundColor: colors.surface}]}>
                <Icon
                  name={inputMode === 'voice' ? 'Keyboard' : 'Mic'}
                  className="w-5 h-5"
                  style={{color: colors.foreground}}
                />
              </TouchableOpacity>

              {inputMode === 'text' ? (
                /* Text input mode */
                <View style={styles.textInputWrapper}>
                  <TextInput
                    style={[
                      styles.textInput,
                      {color: colors.foreground, backgroundColor: colors.surface},
                    ]}
                    placeholder="G√µ c√¢u tr·∫£ l·ªùi..."
                    placeholderTextColor={colors.neutrals400}
                    value={textInput}
                    onChangeText={setTextInput}
                    returnKeyType="send"
                    onSubmitEditing={handleSendText}
                    editable={!isAIResponding}
                  />
                  <TouchableOpacity
                    onPress={handleSendText}
                    disabled={!textInput.trim() || isAIResponding}
                    style={[
                      styles.sendBtn,
                      {
                        backgroundColor:
                          textInput.trim() && !isAIResponding
                            ? speakingColor
                            : `${speakingColor}30`,
                      },
                    ]}>
                    <Icon name="Send" className="w-4 h-4" style={{color: '#FFFFFF'}} />
                  </TouchableOpacity>
                </View>
              ) : (
                /* Voice input mode ‚Äî hold to record */
                <TouchableOpacity
                  onPressIn={handleStartRecording}
                  onPressOut={handleStopRecording}
                  disabled={isAIResponding}
                  activeOpacity={0.7}
                  style={[
                    styles.micBtn,
                    {
                      backgroundColor: isRecording
                        ? '#EF4444'
                        : isAIResponding
                          ? `${speakingColor}40`
                          : speakingColor,
                    },
                  ]}>
                  {isAIResponding ? (
                    <ActivityIndicator size="small" color="#FFFFFF" />
                  ) : (
                    <>
                      <Icon name="Mic" className="w-6 h-6" style={{color: '#FFFFFF'}} />
                      <AppText
                        variant="caption"
                        style={{color: '#FFFFFF', marginTop: 2}}
                        raw>
                        {isRecording ? 'Th·∫£ ƒë·ªÉ g·ª≠i' : 'Gi·ªØ ƒë·ªÉ n√≥i'}
                      </AppText>
                    </>
                  )}
                </TouchableOpacity>
              )}
            </View>
          </View>
        )}
      </KeyboardAvoidingView>
    </SafeAreaView>
  );
}

// =======================
// Styles
// =======================

const styles = StyleSheet.create({
  chatContent: {
    paddingVertical: 12,
    paddingBottom: 20,
  },
  inputArea: {
    paddingHorizontal: 12,
    paddingVertical: 8,
    borderTopWidth: 0.5,
  },
  inputRow: {
    flexDirection: 'row',
    alignItems: 'flex-end',
    gap: 8,
  },
  toggleBtn: {
    width: 44,
    height: 44,
    borderRadius: 22,
    alignItems: 'center',
    justifyContent: 'center',
  },
  textInputWrapper: {
    flex: 1,
    flexDirection: 'row',
    alignItems: 'center',
    gap: 8,
  },
  textInput: {
    flex: 1,
    height: 44,
    borderRadius: 22,
    paddingHorizontal: 16,
    fontSize: 15,
  },
  sendBtn: {
    width: 44,
    height: 44,
    borderRadius: 22,
    alignItems: 'center',
    justifyContent: 'center',
  },
  micBtn: {
    flex: 1,
    height: 56,
    borderRadius: 28,
    alignItems: 'center',
    justifyContent: 'center',
  },
  recordingIndicator: {
    alignItems: 'center',
    paddingVertical: 8,
  },
  endBtn: {
    paddingHorizontal: 12,
    paddingVertical: 6,
    borderRadius: 12,
  },
  endedBanner: {
    alignItems: 'center',
    padding: 20,
    marginHorizontal: 12,
    marginBottom: 12,
    borderRadius: 16,
  },
});
